import polars as pl
import os
from data_catalog import CentralDataCatalog
from materialized_view_manager import MaterializedViewManager
from query_executor import QueryExecutor
from sql_generator import SQLGenerator
from logging_config import init_logger

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from genai import AWSBedrock  # Ensure this is the correct import for AWSBedrock

class TextToSQLAgent:
    def __init__(self, data_catalog_path='data_catalog.json', data_folder='data', max_retries=3):
        # Initialize logging
        init_logger()

        # Load the data catalog
        self.data_catalog = CentralDataCatalog()
        self.data_catalog.load_from_json(data_catalog_path)

        # Load sample data from the specified data folder
        self.dataframes = self.load_sample_data(data_folder)

        # Initialize AWSBedrock instance
        self.aws_bedrock = AWSBedrock()

        # Initialize SQLGenerator with dataframes and data catalog
        self.sql_generator = SQLGenerator(self.aws_bedrock, self.dataframes, self.data_catalog)

        # Initialize MaterializedViewManager
        self.materialized_view_manager = MaterializedViewManager()

        # Initialize QueryExecutor
        self.query_executor = QueryExecutor(self.dataframes, self.sql_generator, max_retries)

    def load_sample_data(self, data_folder):
        """
        Load sample data into Polars DataFrame based on the catalog information.

        Args:
        data_folder (str): The folder where the data files are stored.

        Returns:
        dict: A dictionary of DataFrames where keys are table names.
        """
        dataframes = {}
        for table_name in self.data_catalog.list_tables():
            csv_file = os.path.join(data_folder, f'{table_name}.csv')
            parquet_file = os.path.join(data_folder, f'{table_name}.parquet')

            if os.path.exists(csv_file):
                dataframes[table_name] = pl.read_csv(csv_file)
            elif os.path.exists(parquet_file):
                dataframes[table_name] = pl.read_parquet(parquet_file)
            else:
                raise FileNotFoundError(f"No data file found for table '{table_name}' in folder '{data_folder}'.")

        return dataframes

    def process_prompt(self, user_prompt):
        """
        Process the user's prompt to generate the appropriate response.

        Args:
        user_prompt (str): The prompt provided by the user.

        Returns:
        str: The response generated by the system.
        """
        # Validate and execute the query or generate a direct response
        sql_query, result = self.query_executor.validate_and_execute(user_prompt)

        # Generate a natural language response based on the query result, schema, and descriptions
        text_response = self.query_executor.result_to_text(result, user_prompt, sql_query)
        return text_response
    
if __name__ == "__main__":
    # Initialize the TextToSQLAgent
    agent = TextToSQLAgent()

    # Example user prompt
    user_prompt = "what are the tables"

    # Process the prompt and get the result
    result = agent.process_prompt(user_prompt)
    print(result)
