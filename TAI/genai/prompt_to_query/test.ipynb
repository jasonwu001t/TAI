{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "577db361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from data/products.csv\n",
      "DataFrame loaded from data/users.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'products.csv': shape: (3, 3)\n",
       " ┌─────┬────────────┬───────┐\n",
       " │ id  ┆ name       ┆ price │\n",
       " │ --- ┆ ---        ┆ ---   │\n",
       " │ i64 ┆ str        ┆ i64   │\n",
       " ╞═════╪════════════╪═══════╡\n",
       " │ 1   ┆ Laptop     ┆ 1000  │\n",
       " │ 2   ┆ Smartphone ┆ 800   │\n",
       " │ 3   ┆ Tablet     ┆ 600   │\n",
       " └─────┴────────────┴───────┘,\n",
       " 'users.csv': shape: (3, 3)\n",
       " ┌─────┬───────────────┬───────────────────────────┐\n",
       " │ id  ┆ name          ┆ email                     │\n",
       " │ --- ┆ ---           ┆ ---                       │\n",
       " │ i64 ┆ str           ┆ str                       │\n",
       " ╞═════╪═══════════════╪═══════════════════════════╡\n",
       " │ 1   ┆ John Doe      ┆ john.doe@example.com      │\n",
       " │ 2   ┆ Jane Smith    ┆ jane.smith@example.com    │\n",
       " │ 3   ┆ Emily Johnson ┆ emily.johnson@example.com │\n",
       " └─────┴───────────────┴───────────────────────────┘}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "def load_file(path, use_polars, is_s3=False, s3_client=None):\n",
    "    \"\"\"\n",
    "    Helper function to load a single file, either from a local path or from S3.\n",
    "\n",
    "    Parameters:\n",
    "    - path: The local path or S3 key to the file.\n",
    "    - use_polars: Whether to use Polars instead of Pandas.\n",
    "    - is_s3: If True, load the file from S3.\n",
    "    - s3_client: The Boto3 S3 client, required if is_s3 is True.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame (Polars or Pandas) loaded from the file.\n",
    "    \"\"\"\n",
    "    if is_s3 and s3_client:\n",
    "        response = s3_client.get_object(Bucket=path[0], Key=path[1])\n",
    "        if path[1].endswith('.csv'):\n",
    "            data = response['Body'].read().decode('utf-8')\n",
    "            if use_polars:\n",
    "                return pl.read_csv(BytesIO(data.encode()))\n",
    "            else:\n",
    "                return pd.read_csv(StringIO(data))\n",
    "        elif path[1].endswith('.parquet'):\n",
    "            data = response['Body'].read()\n",
    "            if use_polars:\n",
    "                return pl.read_parquet(BytesIO(data))\n",
    "            else:\n",
    "                return pd.read_parquet(BytesIO(data))\n",
    "    else:\n",
    "        if path.endswith('.csv'):\n",
    "            return pl.read_csv(path) if use_polars else pd.read_csv(path)\n",
    "        elif path.endswith('.parquet'):\n",
    "            return pl.read_parquet(path) if use_polars else pd.read_parquet(path)\n",
    "    raise ValueError(\"File extension not supported. Please use .csv or .parquet.\")\n",
    "\n",
    "def load_s3(bucket_name: str, \n",
    "            s3_directory: str = '',\n",
    "            file_name: str = '', \n",
    "            aws_region: str = 'us-west-2', \n",
    "            use_polars: bool = False, \n",
    "            load_all: bool = False, \n",
    "            selected_files: list = None):\n",
    "    \"\"\"\n",
    "    Loads files from an S3 directory into Pandas or Polars DataFrames. Supports CSV and Parquet formats.\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3', region_name=aws_region)\n",
    "    \n",
    "    if not load_all:\n",
    "        s3_path = f\"{s3_directory}/{file_name}\" if s3_directory else file_name\n",
    "        df = load_file((bucket_name, s3_path), use_polars, is_s3=True, s3_client=s3_client)\n",
    "        print(f\"DataFrame loaded from S3://{bucket_name}/{s3_path}\")\n",
    "        return df\n",
    "    \n",
    "    list_objects = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=s3_directory)\n",
    "    all_files = [obj['Key'] for obj in list_objects.get('Contents', []) if obj['Key'].endswith(('.csv', '.parquet'))]\n",
    "    \n",
    "    if selected_files:\n",
    "        files_to_load = [file for file in all_files if any(file.endswith(selected_file) for selected_file in selected_files)]\n",
    "    else:\n",
    "        files_to_load = all_files\n",
    "\n",
    "    dataframes = {}\n",
    "    for s3_path in files_to_load:\n",
    "        df = load_file((bucket_name, s3_path), use_polars, is_s3=True, s3_client=s3_client)\n",
    "        file_key = os.path.basename(s3_path)\n",
    "        dataframes[file_key] = df\n",
    "        print(f\"DataFrame loaded from S3://{bucket_name}/{s3_path}\")\n",
    "    return dataframes\n",
    "\n",
    "def load_local(data_folder: str, \n",
    "               file_name: str = '', \n",
    "               use_polars: bool = False, \n",
    "               load_all: bool = False, \n",
    "               selected_files: list = None):\n",
    "    \"\"\"\n",
    "    Loads files from a local directory into Pandas or Polars DataFrames. Supports CSV and Parquet formats.\n",
    "    \"\"\"\n",
    "    if not load_all:\n",
    "        local_path = os.path.join(data_folder, file_name)\n",
    "        df = load_file(local_path, use_polars)\n",
    "        print(f\"DataFrame loaded from {local_path}\")\n",
    "        return df\n",
    "\n",
    "    all_files = [f for f in os.listdir(data_folder) if f.endswith(('.csv', '.parquet'))]\n",
    "\n",
    "    if selected_files:\n",
    "        files_to_load = [file for file in all_files if file in selected_files]\n",
    "    else:\n",
    "        files_to_load = all_files\n",
    "\n",
    "    dataframes = {}\n",
    "    for file in files_to_load:\n",
    "        local_path = os.path.join(data_folder, file)\n",
    "        df = load_file(local_path, use_polars)\n",
    "        dataframes[file] = df\n",
    "        print(f\"DataFrame loaded from {local_path}\")\n",
    "    return dataframes\n",
    "\n",
    "# df = load_s3('jtrade1-dir', 'data', 'hhh.csv', use_polars=False)# Single file loading\n",
    "\n",
    "# df\n",
    "# df_dict = load_s3('jtrade1-dir', 'data',use_polars=True, load_all=True) # Massive loading: all files in the directory\n",
    "# df_dict = load_s3('jtrade1-dir', 'data', use_polars=False,load_all=True, selected_files=['hhh.csv', 'eeeee.parquet'])\n",
    "\n",
    "load_local(data_folder='data', \n",
    "               file_name = 'orders.csv', \n",
    "               use_polars = True, \n",
    "               load_all = True, \n",
    "               selected_files = ['products.csv','users.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da319bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92c2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af01fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc78415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('hah.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b369e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.to_s3(bucket_name = 's3://jtrade1-dir/data/',\n",
    "        object_name='hah.csv',\n",
    "        data=df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77c8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data locally\n",
    "df_loaded = data_master.load_from_local('data/2024/07/25/example.csv', 'csv')\n",
    "print(df_loaded)\n",
    "\n",
    "# Save data to S3\n",
    "data_master.save_to_s3('your-bucket-name', 'example.csv', df_example.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f699fc",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock = boto3.client(\n",
    "            service_name='bedrock-runtime',\n",
    "            region_name='us-west-2')\n",
    "prompt = 'canberra is capital of australia'\n",
    "body = json.dumps({\n",
    "    \"inputText\": prompt,\n",
    "})\n",
    "\n",
    "model_id = 'amazon.titan-embed-text-v1'\n",
    "accept = 'application/json'\n",
    "content_type = 'application/json'\n",
    "\n",
    "response = bedrock.invoke_model(\n",
    "                    body=body,\n",
    "                    modelId = model_id,\n",
    "                    accept=accept,\n",
    "                    contentType=content_type)\n",
    "\n",
    "# print (response)\n",
    "response_body = json.loads(response['body'].read())\n",
    "embedding = response_body.get('embedding')\n",
    "print (embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64434e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42971fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_to_sql_agent import TextToSQLAgent\n",
    "\n",
    "agent = TextToSQLAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"what are the customer emails\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"provide me the sql only\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5786fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"some all the ids then minus the sells price\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74da5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"what was my first question\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"generate me a pandas dataframe sample table\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55232f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"select the second column\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ecfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"what is the value of the 3rd column, second value\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cce51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"rename the columsn to city related\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"tell me a story about dragon\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"tell me more about it\"\n",
    "result = agent.process_prompt(user_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TAI.genai import AWSBedrock\n",
    "ab = AWSBedrock()\n",
    "for i in ab.get_active_models():\n",
    "    print (i)\n",
    "#     print (i['modelId'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
